"""
è®­ç»ƒ ResNet æ¨¡å‹ç¤ºä¾‹
"""

import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.backends.cudnn as cudnn
from sklearn.metrics import f1_score

# === è‡ªåŠ¨å°†æ ¹ç›®å½•åŠ å…¥ sys.path ===
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if BASE_DIR not in sys.path:
    sys.path.insert(0, BASE_DIR)

print("DEBUG: sys.path =", sys.path)

# === è¿™é‡Œæ­£å¼å¯¼å…¥ ===
from models.resnet_model import ResNetClassifier
from utils.dataset import get_dataloaders
from utils.visualize import plot_confusion_matrix

print("ResNetClassifier import success!")

# å…³é—­ cudnn è‡ªåŠ¨è°ƒä¼˜ï¼Œé¿å…æ˜¾å­˜ç¢ç‰‡å’Œå¡é¡¿
cudnn.benchmark = False
cudnn.enabled = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# å‚æ•°è®¾ç½®
num_epochs = 10
num_classes = 10
batch_size = 8  # å°ä¸€ç‚¹å‡è½»æ˜¾å­˜å‹åŠ›
learning_rate = 1e-4
data_dir = os.path.join(BASE_DIR, 'data', 'processed', 'train')

print(f"å½“å‰å·¥ä½œç›®å½•ï¼š{os.getcwd()}")
print(f"åŠ è½½è®­ç»ƒæ•°æ®ç›®å½•ï¼š{data_dir}")

# åŠ è½½æ•°æ®ï¼Œnum_workers=0é¿å…Windowså¤šè¿›ç¨‹å¡é¡¿
train_loader, val_loader = get_dataloaders(batch_size=batch_size, data_dir=data_dir, num_workers=0)

model = ResNetClassifier(num_classes=num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

print("[INFO] è¿›å…¥ä¸»å‡½æ•°å…¥å£ ğŸš€")

for epoch in range(num_epochs):
    print(f"\nEpoch [{epoch+1}/{num_epochs}] å¼€å§‹è®­ç»ƒ")
    model.train()
    total_loss = 0
    for i, (images, labels) in enumerate(train_loader):
        print(f"[Epoch {epoch+1}] [Batch {i+1}/{len(train_loader)}] æ•°æ®åŠ è½½å®Œæˆ")
        images, labels = images.to(device), labels.to(device)

        print(f"[Epoch {epoch+1}] [Batch {i+1}] å‰å‘ä¼ æ’­å¼€å§‹")
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        print(f"[Epoch {epoch+1}] [Batch {i+1}] åå‘ä¼ æ’­å¼€å§‹")
        loss.backward()

        print(f"[Epoch {epoch+1}] [Batch {i+1}] ä¼˜åŒ–å™¨æ›´æ–°å¼€å§‹")
        optimizer.step()

        total_loss += loss.item()
        print(f"[Epoch {epoch+1}] [Batch {i+1}] å®Œæˆ, Loss={loss.item():.4f}")

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch [{epoch+1}] å®Œæˆï¼Œå¹³å‡ Loss: {avg_loss:.4f}")

    # éªŒè¯é˜¶æ®µ
    print(f"Epoch [{epoch+1}] å¼€å§‹éªŒè¯")
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    f1 = f1_score(all_labels, all_preds, average='macro')
    print(f"Validation F1-score: {f1:.4f}")

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆä¼šå¼¹å›¾ï¼Œéœ€è¦å¯è§†åŒ–ç¯å¢ƒï¼‰
    plot_confusion_matrix(all_labels, all_preds)

    # è®­ç»ƒå®Œæ¯ä¸ª epoch æ¸…ç†æ˜¾å­˜
    torch.cuda.empty_cache()

# ä¿å­˜æ¨¡å‹
model_path = os.path.join(BASE_DIR, "resnet_best.pth")
torch.save(model.state_dict(), model_path)
print(f"æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")